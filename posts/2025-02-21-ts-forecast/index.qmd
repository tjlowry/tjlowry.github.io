# Time Series Forecasting: First Models in R and Python

In my previous post, I introduced the fundamental concepts of time series forecasting - the importance of domain knowledge, consistent time intervals, and the key components that make up time series data (trend, seasonality, cyclicity, and residuals). Now, let's take the next step and implement some basic forecasting models in both R and Python.

## Why Both R and Python?

While Python has become my go-to language for data science work, I feel R is more intutive for certain aspects of time series forecasting due to the great packages which have been devolped. Each has distinct advantages:

- **R** excels with its purpose-built statistical packages and elegant handling of time series objects
- **Python** offers incredible flexibility, integration with other systems, and powerful machine learning capabilities

Learning both approaches gives you a more complete toolkit and the ability to choose the right tool for each specific forecasting challenge.

## Getting Started with Time Series Data

Before diving into models, we need data. For this example, let's use a classic time series dataset: monthly airline passenger numbers. This dataset shows a clear upward trend and strong seasonality, making it perfect for demonstrating basic forecasting techniques.

## First Models in R

R has specialized libraries designed specifically for time series analysis. The `forecast` package, created by Rob Hyndman, is particularly powerful and user-friendly.

### Example: ARIMA in R

```r
# Install and load necessary packages
install.packages(c("forecast", "tseries"))
library(forecast)
library(tseries)
library(ggplot2)

# Load the airlines dataset (included in R)
data("AirPassengers")
air <- AirPassengers  # Monthly totals of airline passengers from 1949-1960

# Examine the data
class(air)  # Should be "ts" (time series)
frequency(air)  # 12 = monthly data
start(air)  # Starting time period
end(air)  # Ending time period

# Plot the data
autoplot(air) + 
  ggtitle("Monthly Airline Passenger Numbers 1949-1960") + 
  xlab("Year") + 
  ylab("Passengers (thousands)")

# Decompose the time series
air_decomp <- decompose(air, type = "multiplicative")
autoplot(air_decomp)

# Check stationarity with Augmented Dickey-Fuller test
adf.test(air)  # p-value > 0.05 indicates non-stationarity

# Differencing to achieve stationarity
air_diff <- diff(log(air))
adf.test(air_diff)  # Should now be stationary

# Examine ACF and PACF for model parameter selection
acf(air_diff, main="ACF of Differenced Log Passenger Data")
pacf(air_diff, main="PACF of Differenced Log Passenger Data")

# Fit an ARIMA model automatically
air_model <- auto.arima(air, seasonal = TRUE)
summary(air_model)

# Forecast the next 24 months
air_forecast <- forecast(air_model, h = 24)

# Plot the forecast
autoplot(air_forecast) + 
  ggtitle("24-Month Forecast of Airline Passengers")
```

This R example walks through the complete process:
1. Loading and examining the data
2. Visualizing and decomposing the time series
3. Testing for stationarity (crucial for ARIMA models)
4. Using `auto.arima()` to automatically select the best parameters
5. Generating and visualizing a forecast

The `auto.arima()` function automatically determines the appropriate ARIMA model parameters (p, d, q) and their seasonal counterparts (P, D, Q), saving us from manual parameter tuning.

## First Models in Python

Python offers multiple libraries for time series forecasting. The `statsmodels` package provides statistical models while `pandas` handles the data manipulation.

### Example: SARIMA in Python

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.stattools import adfuller
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.statespace.sarimax import SARIMAX
from pandas.plotting import register_matplotlib_converters
register_matplotlib_converters()

# Load the AirPassengers dataset
air = pd.read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv',
                  index_col='Month', parse_dates=True)
air.columns = ['Passengers']

# Plot the data
plt.figure(figsize=(10, 6))
plt.plot(air)
plt.title('Monthly Airline Passenger Numbers 1949-1960')
plt.xlabel('Year')
plt.ylabel('Passengers (thousands)')
plt.grid(True)
plt.tight_layout()
plt.show()

# Decompose the time series
decomposition = seasonal_decompose(air, model='multiplicative')
fig = decomposition.plot()
fig.set_size_inches(10, 8)
plt.tight_layout()
plt.show()

# Check stationarity with Augmented Dickey-Fuller test
def adf_test(series):
    result = adfuller(series.dropna())
    print('ADF Statistic: %f' % result[0])
    print('p-value: %f' % result[1])
    print('Critical Values:')
    for key, value in result[4].items():
        print('\t%s: %.3f' % (key, value))
    if result[1] <= 0.05:
        print("Conclusion: The series is stationary")
    else:
        print("Conclusion: The series is non-stationary")

adf_test(air['Passengers'])

# Take log and difference to make stationary
air['LogPassengers'] = np.log(air['Passengers'])
air['LogDiffPassengers'] = air['LogPassengers'].diff()
adf_test(air['LogDiffPassengers'].dropna())

# Plot ACF and PACF for parameter selection
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))
plot_acf(air['LogDiffPassengers'].dropna(), ax=ax1)
plot_pacf(air['LogDiffPassengers'].dropna(), ax=ax2)
plt.tight_layout()
plt.show()

# Fit a SARIMA model (with parameters based on ACF/PACF)
# For this dataset, a SARIMA(1,1,1)(1,1,1,12) often works well
model = SARIMAX(air['Passengers'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))
results = model.fit()
print(results.summary())

# Forecast the next 24 months
forecast_steps = 24
forecast_index = pd.date_range(start=air.index[-1], periods=forecast_steps+1, freq='MS')[1:]
forecast = results.forecast(forecast_steps)
forecast_df = pd.DataFrame(forecast, index=forecast_index, columns=['Forecast'])

# Plot the actual data and the forecast
plt.figure(figsize=(12, 6))
plt.plot(air['Passengers'], label='Historical data')
plt.plot(forecast_df, label='Forecast')
plt.title('24-Month Forecast of Airline Passengers')
plt.xlabel('Year')
plt.ylabel('Passengers (thousands)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# Calculate and plot confidence intervals
pred = results.get_prediction(start=air.index[-1], end=forecast_index[-1])
pred_conf = pred.conf_int()

plt.figure(figsize=(12, 6))
plt.plot(air['Passengers'], label='Historical data')
plt.plot(pred.predicted_mean, label='Forecast')
plt.fill_between(pred_conf.index, 
                 pred_conf.iloc[:, 0], 
                 pred_conf.iloc[:, 1], 
                 color='k', alpha=0.2)
plt.title('24-Month Forecast with 95% Confidence Interval')
plt.xlabel('Year')
plt.ylabel('Passengers (thousands)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()
```

The Python example follows a similar workflow to the R version, but with Python-specific libraries:

1. Loading data with `pandas`
2. Visualizing with `matplotlib`
3. Decomposing and testing stationarity
4. Fitting a SARIMA model using `statsmodels`
5. Forecasting future values and plotting with confidence intervals

## Key Differences Between R and Python Approaches

As you can see, while the overall process is similar, there are some notable differences:

1. **Data Handling**: R has native support for time series objects, while Python relies on pandas DateTime indexes
2. **Model Selection**: R's `auto.arima()` automatically selects parameters, while in Python we typically need to analyze ACF/PACF plots or use grid search
3. **Visualization**: R's plotting is more concise with the `forecast` package, while Python offers more customization with matplotlib
4. **Performance**: For larger datasets, Python may offer better performance, especially when integrated with other machine learning workflows

## Beyond ARIMA: Next Steps

While ARIMA and SARIMA models are great starting points, there are many other approaches to explore:

- **Exponential Smoothing**: Simple yet powerful, especially for data with strong seasonality
- **Prophet**: Facebook's forecasting tool that handles holidays and events effectively
- **LSTM Networks**: Deep learning approaches for complex sequential patterns
- **XGBoost with Lag Features**: Machine learning with engineered time features

I'll cover these more advanced techniques in future posts, showing implementations in both R and Python where appropriate.

## Wrapping Up

These examples demonstrate basic forecasting models in R and Python, but they're just the beginning. The choice between R and Python often comes down to your specific needs and existing workflow:

- Choose **R** if your work is primarily statistical and you value specialized time series tools
- Choose **Python** if you need integration with larger systems or want to leverage deep learning approaches

In my experience, learning both gives you the most flexibility. Many data scientists start with R for its statistical focus, then migrate to Python as they integrate forecasting into broader data pipelines and applications.

In the next post, I'll dive deeper into model evaluation and selection - how to measure forecast accuracy and choose the right model for your specific time series problem.