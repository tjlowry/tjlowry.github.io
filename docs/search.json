[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Data Science Blog",
    "section": "",
    "text": "Time Series Forecasting: Uncovering Patterns in Your Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTime Series Forecasting: First Models in R and Python\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tyler Lowry",
    "section": "",
    "text": "I’m a Data Science student at BYU-Idaho passionate about turning complex data into actionable insights. With a minor in Accounting and a Machine Learning Certificate, I hope to bridge the gap between business and statistics.\nAt BYU-Idaho, I serve as both a TA/Tutor in the Mathematics Department and Team Lead at the McKay Maclab, which has strengthened my skills in programming, statistics, and leadership.\nAfter graduating in April 2025, I’ll be continuing my education at Texas A&M for a Master’s in Statistical Data Science.\n\n\n\n\n\n\n\n\n\n\n\nPython (Pandas, Polars, Scikit-learn, TensorFlow)\nR\nSQL\n\n\n\n\n\nTableau\nPower BI\nggplot\nPlotly, lets_plot, Seaborn\n\n\n\n\n\n\nSQL Database Optimization\nAWS EC2/S3\nDatabase Design & Architecture\n\n\n\n\n\nPHP (Filament), C#\nJavaScript/TypeScript\nHTML/CSS\n\n\n\n\n\n\n\n\nCheck out my Projects page for a showcase of my recent work"
  },
  {
    "objectID": "index.html#skills",
    "href": "index.html#skills",
    "title": "Tyler Lowry",
    "section": "",
    "text": "Python (Pandas, Polars, Scikit-learn, TensorFlow)\nR\nSQL\n\n\n\n\n\nTableau\nPower BI\nggplot\nPlotly, lets_plot, Seaborn\n\n\n\n\n\n\nSQL Database Optimization\nAWS EC2/S3\nDatabase Design & Architecture\n\n\n\n\n\nPHP (Filament), C#\nJavaScript/TypeScript\nHTML/CSS"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "tjlowry02@gmail.com | LinkedIn"
  },
  {
    "objectID": "resume.html#education",
    "href": "resume.html#education",
    "title": "Resume",
    "section": "Education",
    "text": "Education\nBrigham Young University-Idaho | Rexburg, ID\nBS, Data Science - Accounting Minor - Machine Learning Certificate\nExpected Graduation: April 2025\nGPA: 3.89"
  },
  {
    "objectID": "resume.html#skills",
    "href": "resume.html#skills",
    "title": "Resume",
    "section": "",
    "text": "R, Python, Pandas, Polars, SQL\nMachine Learning, Demand Forecasting, TensorFlow, Scikit-Learn\nTableau, Power BI\n\n\n\n\n\nHTML, CSS, JavaScript, PHP, PySpark\nAPIs, Data Pipelines\nExcel, VBA, Adobe Suite"
  },
  {
    "objectID": "resume.html#professional-experience",
    "href": "resume.html#professional-experience",
    "title": "Resume",
    "section": "Professional Experience",
    "text": "Professional Experience\n\nMachine Learning Engineer Intern | PIC Business Systems\nMay 2023 - Sept 2023 | San Antonio, TX\n\nDeveloped a 90-day sales forecasting ensembled model and an interactive dashboard for product performance, resulting in a 30% improvement in median forecast MAPE\nEnhanced data quality by integrating external factors such as weather and date, using APIs and Pandas to create additional features for the model\nAutomated monthly forecasting and database updates by leveraging AWS Lambda and S3 Buckets, enabling easy access to forecasts and reducing manual efforts\n\n\n\nTA/Tutor | BYU-Idaho Department of Mathematics\nApril 2024 - Present | Rexburg, ID\n\nServed as a teaching assistant and tutor for “Intro to Programming,” “Math for the Real World,” “Data Wrangling and Visualization,” “Data Science Programming,” and “Biostatistics”\nLed group and one-on-one tutoring sessions focused on Python, R, Excel, and statistics\nProvided general data science support at the Data Science Tutoring Lab, assisting students across various data science and statistics courses with Python, R, and other coursework-related questions\n\n\n\nTeam Lead/Developer | BYU-Idaho McKay Maclab\nJan 2023 - Present | Rexburg, ID\n\nCollaborated with a team of 3 in full stack development of Maclab website and 3D printing queue\nConducted interviews, reviewed resumes to screen candidates, and provided training to new employees\nFacilitated weekly meetings to discuss goals, track task progress, and deliver short training sessions to the team\nDesigned interactive streamlit dashboards to track KPI performance, resulting in a 14% average improvement across all metrics\n\n\n\nIntern | George W. Lowry Inc.\nSept 2023 - Dec 2023 | Salida, CA\n\nMigrated legacy database system to AWS and optimized database architecture by eliminating redundant joins, improving foreign key usage, and refining indexes, resulting in a nearly two-hour reduction in report generation runtime\nIdentified and implemented an AWS EC2 instance, increasing computing power while lowering costs, reducing server crashes, and improving efficiency\nDeveloped a CRM using a PHP framework, enhancing location data tracking and streamlining communication between sales team and delivery drivers for improved logistics"
  },
  {
    "objectID": "posts/2024-01-16-machine-learning-forecast/index.html",
    "href": "posts/2024-01-16-machine-learning-forecast/index.html",
    "title": "Building a Sales Forecasting Model",
    "section": "",
    "text": "During my internship at PIC Business Systems, I had the opportunity to develop a sales forecasting model that improved prediction accuracy by 30%. Here’s how I approached it."
  },
  {
    "objectID": "posts/2024-01-16-machine-learning-forecast/index.html#the-challenge",
    "href": "posts/2024-01-16-machine-learning-forecast/index.html#the-challenge",
    "title": "Building a Sales Forecasting Model",
    "section": "The Challenge",
    "text": "The Challenge\nAccurately predicting sales for the next 90 days was crucial for inventory management and business planning. The existing system relied heavily on manual predictions and didn’t account for external factors."
  },
  {
    "objectID": "posts/2024-01-16-machine-learning-forecast/index.html#the-solution",
    "href": "posts/2024-01-16-machine-learning-forecast/index.html#the-solution",
    "title": "Building a Sales Forecasting Model",
    "section": "The Solution",
    "text": "The Solution\nI developed an ensemble model that combined: - XGBoost - Prophet - SARIMA\nThe model incorporated external factors like: - Weather patterns - Seasonal trends - Historical sales data - Market indicators\n[Continue reading for more technical details…]"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Projects",
    "section": "",
    "text": "My Projects\nThis page will be updated soon with projects I have worked on."
  },
  {
    "objectID": "about.html#what-im-passionate-about",
    "href": "about.html#what-im-passionate-about",
    "title": "About Me",
    "section": "",
    "text": "As a Machine Learning Engineer and Developer, I love tackling challenges that combine data science with practical applications. Whether it’s developing sales forecasting models or optimizing database performance, I enjoy seeing how data can drive real business impact."
  },
  {
    "objectID": "about.html#current-role",
    "href": "about.html#current-role",
    "title": "About Me",
    "section": "",
    "text": "At BYU-Idaho, I serve as both a TA/Tutor in the Mathematics Department and Team Lead at the McKay Maclab. I get to combine my technical skills with leadership, whether I’m helping students grasp programming concepts or leading development projects."
  },
  {
    "objectID": "about.html#beyond-the-code",
    "href": "about.html#beyond-the-code",
    "title": "About Me",
    "section": "",
    "text": "When I am not working with data, I love to spend time with my wife and our adopted cat George, a stray we found as a kitten in a California warehouse. I am a huge sports fan and root for all the Arizona-based sports teams even though I’m from San Antonio, TX. I became a fan through my mom, who grew up in Arizona. Some other hobbies of mine are 3d printing, history, and sci-fi."
  },
  {
    "objectID": "about.html#connect-me",
    "href": "about.html#connect-me",
    "title": "About Me",
    "section": "",
    "text": "Connect with me on LinkedIn!"
  },
  {
    "objectID": "posts/2025-02-21-ts-forecast/index.html",
    "href": "posts/2025-02-21-ts-forecast/index.html",
    "title": "Time Series Forecasting: First Models in R and Python",
    "section": "",
    "text": "In my previous post, I introduced the fundamental concepts of time series forecasting - the importance of domain knowledge, consistent time intervals, and the key components that make up time series data (trend, seasonality, cyclicity, and residuals). Now, let’s take the next step and implement some basic forecasting models in both R and Python.\n\n\nWhile Python has become my go-to language for data science work, I feel R is more intutive for certain aspects of time series forecasting due to the great packages which have been devolped. Each has distinct advantages:\n\nR excels with its purpose-built statistical packages and elegant handling of time series objects\nPython offers incredible flexibility, integration with other systems, and powerful machine learning capabilities\n\nLearning both approaches gives you a more complete toolkit and the ability to choose the right tool for each specific forecasting challenge.\n\n\n\nBefore diving into models, we need data. For this example, let’s use a classic time series dataset: monthly airline passenger numbers. This dataset shows a clear upward trend and strong seasonality, making it perfect for demonstrating basic forecasting techniques.\n\n\n\nR has specialized libraries designed specifically for time series analysis. The forecast package, created by Rob Hyndman, is particularly powerful and user-friendly.\n\n\n# Install and load necessary packages\ninstall.packages(c(\"forecast\", \"tseries\"))\nlibrary(forecast)\nlibrary(tseries)\nlibrary(ggplot2)\n\n# Load the airlines dataset (included in R)\ndata(\"AirPassengers\")\nair &lt;- AirPassengers  # Monthly totals of airline passengers from 1949-1960\n\n# Examine the data\nclass(air)  # Should be \"ts\" (time series)\nfrequency(air)  # 12 = monthly data\nstart(air)  # Starting time period\nend(air)  # Ending time period\n\n# Plot the data\nautoplot(air) + \n  ggtitle(\"Monthly Airline Passenger Numbers 1949-1960\") + \n  xlab(\"Year\") + \n  ylab(\"Passengers (thousands)\")\n\n# Decompose the time series\nair_decomp &lt;- decompose(air, type = \"multiplicative\")\nautoplot(air_decomp)\n\n# Check stationarity with Augmented Dickey-Fuller test\nadf.test(air)  # p-value &gt; 0.05 indicates non-stationarity\n\n# Differencing to achieve stationarity\nair_diff &lt;- diff(log(air))\nadf.test(air_diff)  # Should now be stationary\n\n# Examine ACF and PACF for model parameter selection\nacf(air_diff, main=\"ACF of Differenced Log Passenger Data\")\npacf(air_diff, main=\"PACF of Differenced Log Passenger Data\")\n\n# Fit an ARIMA model automatically\nair_model &lt;- auto.arima(air, seasonal = TRUE)\nsummary(air_model)\n\n# Forecast the next 24 months\nair_forecast &lt;- forecast(air_model, h = 24)\n\n# Plot the forecast\nautoplot(air_forecast) + \n  ggtitle(\"24-Month Forecast of Airline Passengers\")\nThis R example walks through the complete process: 1. Loading and examining the data 2. Visualizing and decomposing the time series 3. Testing for stationarity (crucial for ARIMA models) 4. Using auto.arima() to automatically select the best parameters 5. Generating and visualizing a forecast\nThe auto.arima() function automatically determines the appropriate ARIMA model parameters (p, d, q) and their seasonal counterparts (P, D, Q), saving us from manual parameter tuning.\n\n\n\n\nPython offers multiple libraries for time series forecasting. The statsmodels package provides statistical models while pandas handles the data manipulation.\n\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\n\n# Load the AirPassengers dataset\nair = pd.read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv',\n                  index_col='Month', parse_dates=True)\nair.columns = ['Passengers']\n\n# Plot the data\nplt.figure(figsize=(10, 6))\nplt.plot(air)\nplt.title('Monthly Airline Passenger Numbers 1949-1960')\nplt.xlabel('Year')\nplt.ylabel('Passengers (thousands)')\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n# Decompose the time series\ndecomposition = seasonal_decompose(air, model='multiplicative')\nfig = decomposition.plot()\nfig.set_size_inches(10, 8)\nplt.tight_layout()\nplt.show()\n\n# Check stationarity with Augmented Dickey-Fuller test\ndef adf_test(series):\n    result = adfuller(series.dropna())\n    print('ADF Statistic: %f' % result[0])\n    print('p-value: %f' % result[1])\n    print('Critical Values:')\n    for key, value in result[4].items():\n        print('\\t%s: %.3f' % (key, value))\n    if result[1] &lt;= 0.05:\n        print(\"Conclusion: The series is stationary\")\n    else:\n        print(\"Conclusion: The series is non-stationary\")\n\nadf_test(air['Passengers'])\n\n# Take log and difference to make stationary\nair['LogPassengers'] = np.log(air['Passengers'])\nair['LogDiffPassengers'] = air['LogPassengers'].diff()\nadf_test(air['LogDiffPassengers'].dropna())\n\n# Plot ACF and PACF for parameter selection\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\nplot_acf(air['LogDiffPassengers'].dropna(), ax=ax1)\nplot_pacf(air['LogDiffPassengers'].dropna(), ax=ax2)\nplt.tight_layout()\nplt.show()\n\n# Fit a SARIMA model (with parameters based on ACF/PACF)\n# For this dataset, a SARIMA(1,1,1)(1,1,1,12) often works well\nmodel = SARIMAX(air['Passengers'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\nresults = model.fit()\nprint(results.summary())\n\n# Forecast the next 24 months\nforecast_steps = 24\nforecast_index = pd.date_range(start=air.index[-1], periods=forecast_steps+1, freq='MS')[1:]\nforecast = results.forecast(forecast_steps)\nforecast_df = pd.DataFrame(forecast, index=forecast_index, columns=['Forecast'])\n\n# Plot the actual data and the forecast\nplt.figure(figsize=(12, 6))\nplt.plot(air['Passengers'], label='Historical data')\nplt.plot(forecast_df, label='Forecast')\nplt.title('24-Month Forecast of Airline Passengers')\nplt.xlabel('Year')\nplt.ylabel('Passengers (thousands)')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n# Calculate and plot confidence intervals\npred = results.get_prediction(start=air.index[-1], end=forecast_index[-1])\npred_conf = pred.conf_int()\n\nplt.figure(figsize=(12, 6))\nplt.plot(air['Passengers'], label='Historical data')\nplt.plot(pred.predicted_mean, label='Forecast')\nplt.fill_between(pred_conf.index, \n                 pred_conf.iloc[:, 0], \n                 pred_conf.iloc[:, 1], \n                 color='k', alpha=0.2)\nplt.title('24-Month Forecast with 95% Confidence Interval')\nplt.xlabel('Year')\nplt.ylabel('Passengers (thousands)')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\nThe Python example follows a similar workflow to the R version, but with Python-specific libraries:\n\nLoading data with pandas\nVisualizing with matplotlib\nDecomposing and testing stationarity\nFitting a SARIMA model using statsmodels\nForecasting future values and plotting with confidence intervals\n\n\n\n\n\nAs you can see, while the overall process is similar, there are some notable differences:\n\nData Handling: R has native support for time series objects, while Python relies on pandas DateTime indexes\nModel Selection: R’s auto.arima() automatically selects parameters, while in Python we typically need to analyze ACF/PACF plots or use grid search\nVisualization: R’s plotting is more concise with the forecast package, while Python offers more customization with matplotlib\nPerformance: For larger datasets, Python may offer better performance, especially when integrated with other machine learning workflows\n\n\n\n\nWhile ARIMA and SARIMA models are great starting points, there are many other approaches to explore:\n\nExponential Smoothing: Simple yet powerful, especially for data with strong seasonality\nProphet: Facebook’s forecasting tool that handles holidays and events effectively\nLSTM Networks: Deep learning approaches for complex sequential patterns\nXGBoost with Lag Features: Machine learning with engineered time features\n\nI’ll cover these more advanced techniques in future posts, showing implementations in both R and Python where appropriate.\n\n\n\nThese examples demonstrate basic forecasting models in R and Python, but they’re just the beginning. The choice between R and Python often comes down to your specific needs and existing workflow:\n\nChoose R if your work is primarily statistical and you value specialized time series tools\nChoose Python if you need integration with larger systems or want to leverage deep learning approaches\n\nIn my experience, learning both gives you the most flexibility. Many data scientists start with R for its statistical focus, then migrate to Python as they integrate forecasting into broader data pipelines and applications.\nIn the next post, I’ll dive deeper into model evaluation and selection - how to measure forecast accuracy and choose the right model for your specific time series problem."
  },
  {
    "objectID": "posts/2025-02-21-ts-forecast/index.html#why-both-r-and-python",
    "href": "posts/2025-02-21-ts-forecast/index.html#why-both-r-and-python",
    "title": "Time Series Forecasting: First Models in R and Python",
    "section": "",
    "text": "While Python has become my go-to language for data science work, I feel R is more intutive for certain aspects of time series forecasting due to the great packages which have been devolped. Each has distinct advantages:\n\nR excels with its purpose-built statistical packages and elegant handling of time series objects\nPython offers incredible flexibility, integration with other systems, and powerful machine learning capabilities\n\nLearning both approaches gives you a more complete toolkit and the ability to choose the right tool for each specific forecasting challenge."
  },
  {
    "objectID": "posts/2025-02-21-ts-forecast/index.html#getting-started-with-time-series-data",
    "href": "posts/2025-02-21-ts-forecast/index.html#getting-started-with-time-series-data",
    "title": "Time Series Forecasting: First Models in R and Python",
    "section": "",
    "text": "Before diving into models, we need data. For this example, let’s use a classic time series dataset: monthly airline passenger numbers. This dataset shows a clear upward trend and strong seasonality, making it perfect for demonstrating basic forecasting techniques."
  },
  {
    "objectID": "posts/2025-02-21-ts-forecast/index.html#first-models-in-r",
    "href": "posts/2025-02-21-ts-forecast/index.html#first-models-in-r",
    "title": "Time Series Forecasting: First Models in R and Python",
    "section": "",
    "text": "R has specialized libraries designed specifically for time series analysis. The forecast package, created by Rob Hyndman, is particularly powerful and user-friendly.\n\n\n# Install and load necessary packages\ninstall.packages(c(\"forecast\", \"tseries\"))\nlibrary(forecast)\nlibrary(tseries)\nlibrary(ggplot2)\n\n# Load the airlines dataset (included in R)\ndata(\"AirPassengers\")\nair &lt;- AirPassengers  # Monthly totals of airline passengers from 1949-1960\n\n# Examine the data\nclass(air)  # Should be \"ts\" (time series)\nfrequency(air)  # 12 = monthly data\nstart(air)  # Starting time period\nend(air)  # Ending time period\n\n# Plot the data\nautoplot(air) + \n  ggtitle(\"Monthly Airline Passenger Numbers 1949-1960\") + \n  xlab(\"Year\") + \n  ylab(\"Passengers (thousands)\")\n\n# Decompose the time series\nair_decomp &lt;- decompose(air, type = \"multiplicative\")\nautoplot(air_decomp)\n\n# Check stationarity with Augmented Dickey-Fuller test\nadf.test(air)  # p-value &gt; 0.05 indicates non-stationarity\n\n# Differencing to achieve stationarity\nair_diff &lt;- diff(log(air))\nadf.test(air_diff)  # Should now be stationary\n\n# Examine ACF and PACF for model parameter selection\nacf(air_diff, main=\"ACF of Differenced Log Passenger Data\")\npacf(air_diff, main=\"PACF of Differenced Log Passenger Data\")\n\n# Fit an ARIMA model automatically\nair_model &lt;- auto.arima(air, seasonal = TRUE)\nsummary(air_model)\n\n# Forecast the next 24 months\nair_forecast &lt;- forecast(air_model, h = 24)\n\n# Plot the forecast\nautoplot(air_forecast) + \n  ggtitle(\"24-Month Forecast of Airline Passengers\")\nThis R example walks through the complete process: 1. Loading and examining the data 2. Visualizing and decomposing the time series 3. Testing for stationarity (crucial for ARIMA models) 4. Using auto.arima() to automatically select the best parameters 5. Generating and visualizing a forecast\nThe auto.arima() function automatically determines the appropriate ARIMA model parameters (p, d, q) and their seasonal counterparts (P, D, Q), saving us from manual parameter tuning."
  },
  {
    "objectID": "posts/2025-02-21-ts-forecast/index.html#first-models-in-python",
    "href": "posts/2025-02-21-ts-forecast/index.html#first-models-in-python",
    "title": "Time Series Forecasting: First Models in R and Python",
    "section": "",
    "text": "Python offers multiple libraries for time series forecasting. The statsmodels package provides statistical models while pandas handles the data manipulation.\n\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\n\n# Load the AirPassengers dataset\nair = pd.read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv',\n                  index_col='Month', parse_dates=True)\nair.columns = ['Passengers']\n\n# Plot the data\nplt.figure(figsize=(10, 6))\nplt.plot(air)\nplt.title('Monthly Airline Passenger Numbers 1949-1960')\nplt.xlabel('Year')\nplt.ylabel('Passengers (thousands)')\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n# Decompose the time series\ndecomposition = seasonal_decompose(air, model='multiplicative')\nfig = decomposition.plot()\nfig.set_size_inches(10, 8)\nplt.tight_layout()\nplt.show()\n\n# Check stationarity with Augmented Dickey-Fuller test\ndef adf_test(series):\n    result = adfuller(series.dropna())\n    print('ADF Statistic: %f' % result[0])\n    print('p-value: %f' % result[1])\n    print('Critical Values:')\n    for key, value in result[4].items():\n        print('\\t%s: %.3f' % (key, value))\n    if result[1] &lt;= 0.05:\n        print(\"Conclusion: The series is stationary\")\n    else:\n        print(\"Conclusion: The series is non-stationary\")\n\nadf_test(air['Passengers'])\n\n# Take log and difference to make stationary\nair['LogPassengers'] = np.log(air['Passengers'])\nair['LogDiffPassengers'] = air['LogPassengers'].diff()\nadf_test(air['LogDiffPassengers'].dropna())\n\n# Plot ACF and PACF for parameter selection\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\nplot_acf(air['LogDiffPassengers'].dropna(), ax=ax1)\nplot_pacf(air['LogDiffPassengers'].dropna(), ax=ax2)\nplt.tight_layout()\nplt.show()\n\n# Fit a SARIMA model (with parameters based on ACF/PACF)\n# For this dataset, a SARIMA(1,1,1)(1,1,1,12) often works well\nmodel = SARIMAX(air['Passengers'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\nresults = model.fit()\nprint(results.summary())\n\n# Forecast the next 24 months\nforecast_steps = 24\nforecast_index = pd.date_range(start=air.index[-1], periods=forecast_steps+1, freq='MS')[1:]\nforecast = results.forecast(forecast_steps)\nforecast_df = pd.DataFrame(forecast, index=forecast_index, columns=['Forecast'])\n\n# Plot the actual data and the forecast\nplt.figure(figsize=(12, 6))\nplt.plot(air['Passengers'], label='Historical data')\nplt.plot(forecast_df, label='Forecast')\nplt.title('24-Month Forecast of Airline Passengers')\nplt.xlabel('Year')\nplt.ylabel('Passengers (thousands)')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n# Calculate and plot confidence intervals\npred = results.get_prediction(start=air.index[-1], end=forecast_index[-1])\npred_conf = pred.conf_int()\n\nplt.figure(figsize=(12, 6))\nplt.plot(air['Passengers'], label='Historical data')\nplt.plot(pred.predicted_mean, label='Forecast')\nplt.fill_between(pred_conf.index, \n                 pred_conf.iloc[:, 0], \n                 pred_conf.iloc[:, 1], \n                 color='k', alpha=0.2)\nplt.title('24-Month Forecast with 95% Confidence Interval')\nplt.xlabel('Year')\nplt.ylabel('Passengers (thousands)')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\nThe Python example follows a similar workflow to the R version, but with Python-specific libraries:\n\nLoading data with pandas\nVisualizing with matplotlib\nDecomposing and testing stationarity\nFitting a SARIMA model using statsmodels\nForecasting future values and plotting with confidence intervals"
  },
  {
    "objectID": "posts/2025-02-21-ts-forecast/index.html#key-differences-between-r-and-python-approaches",
    "href": "posts/2025-02-21-ts-forecast/index.html#key-differences-between-r-and-python-approaches",
    "title": "Time Series Forecasting: First Models in R and Python",
    "section": "",
    "text": "As you can see, while the overall process is similar, there are some notable differences:\n\nData Handling: R has native support for time series objects, while Python relies on pandas DateTime indexes\nModel Selection: R’s auto.arima() automatically selects parameters, while in Python we typically need to analyze ACF/PACF plots or use grid search\nVisualization: R’s plotting is more concise with the forecast package, while Python offers more customization with matplotlib\nPerformance: For larger datasets, Python may offer better performance, especially when integrated with other machine learning workflows"
  },
  {
    "objectID": "posts/2025-02-21-ts-forecast/index.html#beyond-arima-next-steps",
    "href": "posts/2025-02-21-ts-forecast/index.html#beyond-arima-next-steps",
    "title": "Time Series Forecasting: First Models in R and Python",
    "section": "",
    "text": "While ARIMA and SARIMA models are great starting points, there are many other approaches to explore:\n\nExponential Smoothing: Simple yet powerful, especially for data with strong seasonality\nProphet: Facebook’s forecasting tool that handles holidays and events effectively\nLSTM Networks: Deep learning approaches for complex sequential patterns\nXGBoost with Lag Features: Machine learning with engineered time features\n\nI’ll cover these more advanced techniques in future posts, showing implementations in both R and Python where appropriate."
  },
  {
    "objectID": "posts/2025-02-21-ts-forecast/index.html#wrapping-up",
    "href": "posts/2025-02-21-ts-forecast/index.html#wrapping-up",
    "title": "Time Series Forecasting: First Models in R and Python",
    "section": "",
    "text": "These examples demonstrate basic forecasting models in R and Python, but they’re just the beginning. The choice between R and Python often comes down to your specific needs and existing workflow:\n\nChoose R if your work is primarily statistical and you value specialized time series tools\nChoose Python if you need integration with larger systems or want to leverage deep learning approaches\n\nIn my experience, learning both gives you the most flexibility. Many data scientists start with R for its statistical focus, then migrate to Python as they integrate forecasting into broader data pipelines and applications.\nIn the next post, I’ll dive deeper into model evaluation and selection - how to measure forecast accuracy and choose the right model for your specific time series problem."
  },
  {
    "objectID": "posts/2025-01-27-machine-learning-forecast/index.html",
    "href": "posts/2025-01-27-machine-learning-forecast/index.html",
    "title": "Time Series Forecasting: Uncovering Patterns in Your Data",
    "section": "",
    "text": "Time series forecasting is a fascinating part of data science and machine learning. I first encountered it during a machine learning course where we briefly covered various models and techniques like classification, regression, random forests, LSTMs, CNNs, and gradient boosted models. In that class I was tasked with predicting bike sales. When I mentioned what I was learning to a family member, they asked if these techniques could be applied to demand forecasting in the context of their specific business. I thought it couldnt too different from what I did in class, and said yes. I quickly discovered the depth and complexity of time series forecasting was so much greater then what I had thought before.\n\n\nThe MOST important step when approaching time series forecasting is researching the domain your data comes from. If you’re working with sales data from a janitorial products warehouse, take time to understand that industry. Talk to people working in it to discover the key factors driving their sales. This domain knowledge will be invaluable as you build your models and interpret results.\n\n\n\nWhat exactly is time series forecasting? Life is full of patterns - we find them in nature, buildings, and data. Time series forecasting extracts patterns from historical data to predict future outcomes. The defining characteristic is the time element: measurements recorded at consistent intervals, whether minutes, hours, days, weeks, or months. Consistency is crucial - if your data sometimes uses daily measurements and other times weekly, you must standardize to a single time unit before analysis.\n\n\n\nOnce your data is properly structured with consistent time intervals, you can begin identifying patterns and sepearating the data into its different compenents through a process called decomposition. Time series data typically contains four main components:\n\n\nThe long-term progression of your series - whether values are generally increasing, decreasing, or remaining stable over time. Trends represent the underlying direction of your data.\n\n\n\nRepeating patterns that occur at regular intervals. These might be daily, weekly, monthly, or yearly cycles depending on your data. Holiday shopping spikes in retail or specific times of yar being know for having more storms are examples of seasonality.\n\n\n\nLonger-term patterns that don’t have a fixed frequency. Economic cycles that affect business performance over several years are a classic example, where boom and bust periods create waves in the data.\n\n\n\nThe random variation remaining after accounting for trend, seasonality, and cyclicity. This represents unpredictable fluctuations that can’t be explained by the model.\nThese components combine (either additively or multiplicatively) to create the overall time series pattern.\n\n\n\n\nAfter decomposing your time series, you can use this information to make better predictions. Trends and seasonal patterns often become very noticeable - perhaps sales peak annually during the holiday season or just before school starts.\nThis is why domain knowledge is so critical. Understanding external factors like natural disasters, company sales strategies, or market conditions helps explain outliers, spikes, or dips that might otherwise confuse your model. Without this context, you risk misinterpreting the data or making incorrect forecasts.\nWhen you combine solid statistical techniques with domain understanding, time series forecasting becomes a powerful tool for business planning, resource usage, and strategic decision-making.\n\n\n\nIn this post I introduced some of the foundational ideas of time series forecasting, like what it is and what parts up make up a time series. I will be making additional posts that go more indepth about the application of these ideas and other concepts crucial to time series forecasting."
  },
  {
    "objectID": "posts/2025-01-27-machine-learning-forecast/index.html#before-you-start-coding",
    "href": "posts/2025-01-27-machine-learning-forecast/index.html#before-you-start-coding",
    "title": "Time Series Forecasting: Uncovering Patterns in Your Data",
    "section": "",
    "text": "The MOST important step when approaching time series forecasting is researching the domain your data comes from. If you’re working with sales data from a janitorial products warehouse, take time to understand that industry. Talk to people working in it to discover the key factors driving their sales. This domain knowledge will be invaluable as you build your models and interpret results."
  },
  {
    "objectID": "posts/2025-01-27-machine-learning-forecast/index.html#the-basics",
    "href": "posts/2025-01-27-machine-learning-forecast/index.html#the-basics",
    "title": "Time Series Forecasting: Uncovering Patterns in Your Data",
    "section": "",
    "text": "What exactly is time series forecasting? Life is full of patterns - we find them in nature, buildings, and data. Time series forecasting extracts patterns from historical data to predict future outcomes. The defining characteristic is the time element: measurements recorded at consistent intervals, whether minutes, hours, days, weeks, or months. Consistency is crucial - if your data sometimes uses daily measurements and other times weekly, you must standardize to a single time unit before analysis."
  },
  {
    "objectID": "posts/2025-01-27-machine-learning-forecast/index.html#extracting-the-patterns",
    "href": "posts/2025-01-27-machine-learning-forecast/index.html#extracting-the-patterns",
    "title": "Time Series Forecasting: Uncovering Patterns in Your Data",
    "section": "",
    "text": "Once your data is properly structured with consistent time intervals, you can begin identifying patterns and sepearating the data into its different compenents through a process called decomposition. Time series data typically contains four main components:\n\n\nThe long-term progression of your series - whether values are generally increasing, decreasing, or remaining stable over time. Trends represent the underlying direction of your data.\n\n\n\nRepeating patterns that occur at regular intervals. These might be daily, weekly, monthly, or yearly cycles depending on your data. Holiday shopping spikes in retail or specific times of yar being know for having more storms are examples of seasonality.\n\n\n\nLonger-term patterns that don’t have a fixed frequency. Economic cycles that affect business performance over several years are a classic example, where boom and bust periods create waves in the data.\n\n\n\nThe random variation remaining after accounting for trend, seasonality, and cyclicity. This represents unpredictable fluctuations that can’t be explained by the model.\nThese components combine (either additively or multiplicatively) to create the overall time series pattern."
  },
  {
    "objectID": "posts/2025-01-27-machine-learning-forecast/index.html#understanding-the-patterns",
    "href": "posts/2025-01-27-machine-learning-forecast/index.html#understanding-the-patterns",
    "title": "Time Series Forecasting: Uncovering Patterns in Your Data",
    "section": "",
    "text": "After decomposing your time series, you can use this information to make better predictions. Trends and seasonal patterns often become very noticeable - perhaps sales peak annually during the holiday season or just before school starts.\nThis is why domain knowledge is so critical. Understanding external factors like natural disasters, company sales strategies, or market conditions helps explain outliers, spikes, or dips that might otherwise confuse your model. Without this context, you risk misinterpreting the data or making incorrect forecasts.\nWhen you combine solid statistical techniques with domain understanding, time series forecasting becomes a powerful tool for business planning, resource usage, and strategic decision-making."
  },
  {
    "objectID": "posts/2025-01-27-machine-learning-forecast/index.html#looking-ahead",
    "href": "posts/2025-01-27-machine-learning-forecast/index.html#looking-ahead",
    "title": "Time Series Forecasting: Uncovering Patterns in Your Data",
    "section": "",
    "text": "In this post I introduced some of the foundational ideas of time series forecasting, like what it is and what parts up make up a time series. I will be making additional posts that go more indepth about the application of these ideas and other concepts crucial to time series forecasting."
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Tyler Lowry",
    "section": "About Me",
    "text": "About Me\nAt BYU-Idaho, I serve as both a TA/Tutor in the Mathematics Department and Team Lead at the McKay Maclab, which has strengthened my skills in programming, statistics, and leadership.\nAfter graduating in April 2025, I’ll be continuing my education at Texas A&M in the Statistics Department for a Master’s in Statistical Data Science."
  },
  {
    "objectID": "index.html#featured-projects",
    "href": "index.html#featured-projects",
    "title": "Tyler Lowry",
    "section": "",
    "text": "Check out my Projects page for a showcase of my recent work"
  },
  {
    "objectID": "resume.html#technical-skills",
    "href": "resume.html#technical-skills",
    "title": "Resume",
    "section": "Technical Skills",
    "text": "Technical Skills\n\n\n\nData Science\n\nPython (Pandas, Polars), R (Tidyverse)\nMachine Learning (TensorFlow, Scikit-Learn), Demand Forecasting\nVisualization (Tableau, Power BI, ggplot2)\n\n\n\n\nDevelopment & Engineering\n\nHTML, CSS, JavaScript, TypeScript, PHP, C#\nAPIs, ETL Pipelines, PySpark, SQL\nExcel/VBA, Adobe Suite, Microsoft Office"
  },
  {
    "objectID": "resume.html#tyler-lowry",
    "href": "resume.html#tyler-lowry",
    "title": "Resume",
    "section": "",
    "text": "tjlowry02@gmail.com | LinkedIn"
  }
]